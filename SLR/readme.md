{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression from Scratch\n",
    "\n",
    "## Introduction\n",
    "This repository implements **Simple Linear Regression (SLR) from scratch** without using `sklearn`. It includes data generation, model training using **Gradient Descent**, and model evaluation using **Mean Squared Error (MSE)**.\n",
    "\n",
    "## Equations Used\n",
    "### 1. Simple Linear Regression Equation\n",
    "The equation for simple linear regression is:\n",
    "\\[ y = mX + c \\]\n",
    "where:\n",
    "- \\( m \\) is the **slope** (coefficient of X)\n",
    "- \\( c \\) is the **intercept** (bias term)\n",
    "- \\( X \\) is the **input feature**\n",
    "- \\( y \\) is the **predicted output**\n",
    "\n",
    "### 2. Mean Squared Error (MSE)\n",
    "The Mean Squared Error is used as the loss function:\n",
    "\\[ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 \\]\n",
    "where:\n",
    "- \\( y_i \\) is the actual target value\n",
    "- \\( \\hat{y}_i \\) is the predicted value\n",
    "- \\( n \\) is the number of data points\n",
    "\n",
    "### 3. Gradient Descent\n",
    "To optimize \\( m \\) and \\( c \\), we use **Gradient Descent**:\n",
    "#### Partial Derivatives:\n",
    "\\[ \\frac{\\partial J}{\\partial m} = \\frac{-2}{n} \\sum X (y - \\hat{y}) \\]\n",
    "\\[ \\frac{\\partial J}{\\partial c} = \\frac{-2}{n} \\sum (y - \\hat{y}) \\]\n",
    "\n",
    "#### Updating Equations:\n",
    "\\[ m = m - \\alpha \\frac{\\partial J}{\\partial m} \\]\n",
    "\\[ c = c - \\alpha \\frac{\\partial J}{\\partial c} \\]\n",
    "where \\( \\alpha \\) is the **learning rate**.\n",
    "\n",
    "## Code Structure\n",
    "- **`generate_data(n_samples, test_size)`** → Generates synthetic data\n",
    "- **`compute_loss(y_true, y_pred)`** → Computes Mean Squared Error\n",
    "- **`compute_gradients(x, y, slope, intercept)`** → Computes gradients for \\( m \\) and \\( c \\)\n",
    "- **`predict(x, m, c)`** → Predicts target values\n",
    "- **`plot_loss(loss_history)`** → Plots training loss\n",
    "- **`plot_regression_line(X, y, m, c)`** → Plots best-fit line\n",
    "- **`fit(x, y, alpha, epochs)`** → Runs Gradient Descent algorithm\n",
    "\n",
    "## Installation\n",
    "```bash\n",
    "pip install numpy matplotlib tqdm scikit-learn\n",
    "```\n",
    "\n",
    "## Usage\n",
    "```python\n",
    "python slr.py\n",
    "```\n",
    "\n",
    "## Example Output\n",
    "```\n",
    "Final parameters: m = 2.45, c = 5.12\n",
    "Mean Squared Error: 3.05\n",
    "```\n",
    "\n",
    "## Visualization\n",
    "1. **Loss vs. Epochs**: Shows how loss decreases over training iterations.\n",
    "2. **Regression Line**: Displays the best-fit line against actual data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
